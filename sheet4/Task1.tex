Considering the exercise's dataset, we can build the following $X$ Matrix:\\
\\
$X = \begin{Bmatrix}
	3 & 1 & 1 \\
	6.5 & 1 & 1.5\\
	5.5 & 3 & 2.5\\
	0.5 & -1 & -0.5\\
	-0.5 & 1 & 0.5
\end{Bmatrix}$\\
\\
By centering the matrix, we get the following $X_{cen}$ matrix:\\
\\
$X_{cen} = \begin{Bmatrix}
0 & 0 & 0 \\
3.5 & 0 & 0.5\\
2.5 & 2 & 1.5\\
-2.5 & -2 & -1.5\\
-3.5 & 0 &-0.5
\end{Bmatrix}$\\
\\
After centering the matrix, our goal is to compute the covariance matrix. We represented it as $C:$\\
\\
$C = \begin{Bmatrix}
37 & 10 & 11 \\
10 & 8 & 6\\
11 & 6 & 5\\
\end{Bmatrix}$\\
\\
The following step was to find the \textbf{eigenvalues} and \textbf{eigenvectors}:
\begin{verbatim}
Eigenvalues:
[[-0.0000, 0, 0]
[0, 6.0000, 0]
[0, 0, 44.0000]]

Eigenvectors:
[[-0.1231 -0.4082  -0.9045]
[-0.4924  0.8165 -0.3015]
[0.8616  0.4082  -0.3015]]

\end{verbatim}

\subsection{Reducing for 2-Dim}
The $W$ for the new 2-dimensional space:\\
\\
$W = \begin{Bmatrix}
-0.9045 & -0.4082\\
-0.3015 & 0.8165\\
-0.3015 & 0.4082
\end{Bmatrix}$\\
\\
By right multiplying it with $X_{cen}$ we get:\\ 
\\
$X_{2-dim}$ = $X_{cen}*W$ = $\begin{Bmatrix}
0 & 0\\
-3.3166 & -1.2247\\
-3.3166 & 1.2247\\
3.3166 & -1.2247\\
3.3166 & 1.2247
\end{Bmatrix}$
\\

\subsection{Reducing for 1-Dim}
The $W$ for the new 1-dimensional space:\\
\\
$W = \begin{Bmatrix}
-0.9045\\
-0.3015\\
-0.3015
\end{Bmatrix}$\\
\\
By right multiplying it with $X_{std}$ we get:\\ 
\\
$X_{1-dim}$ = $X_{cen}*W$ = $\begin{Bmatrix}
-3.3166\\
-6.6332\\
-6.6332\\
0.0000\\
-0.0000
\end{Bmatrix}$
\\



